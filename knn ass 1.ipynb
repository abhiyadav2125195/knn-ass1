{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb8c3b8-3d73-41c5-a5db-43c2a3f6fc03",
   "metadata": {},
   "source": [
    "# Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014d4bc-1501-495d-92ea-72afbf79bfda",
   "metadata": {},
   "source": [
    "KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for classification and regression tasks. It is a non-parametric and instance-based learning method. In KNN, the class or value of a data point is determined by the majority class or the average of the values of its k nearest neighbors in the feature space. KNN works on the principle that similar data points tend to have similar outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48dd48-52a2-45ea-bfb5-1df8285b0861",
   "metadata": {},
   "source": [
    "# Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0453b-9adc-421f-8d7b-e54d101f1c90",
   "metadata": {},
   "source": [
    "The choice of the value of K in KNN is crucial as it can significantly impact the algorithm's performance. A small K (e.g., 1 or 3) can make the model sensitive to noise, while a large K can lead to overly smooth decision boundaries. To choose an appropriate K:\n",
    "Use cross-validation techniques like k-fold cross-validation to evaluate different values of K and choose the one that gives the best performance.\n",
    "Consider the nature of your data and problem. Larger K values may work better for smoother data, while smaller K values may be suitable for noisy data.\n",
    "Experiment with different K values and observe how they affect the model's accuracy and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e34ee0-f9e1-4f9d-8f8a-b54e9cd3c22d",
   "metadata": {},
   "source": [
    "# Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bcff2-a5d1-471a-a9ca-ca67342e48c3",
   "metadata": {},
   "source": [
    "KNN Classifier: KNN is used as a classifier when the task is to assign a class label to a data point. The class assigned is based on the majority class among the k nearest neighbors.\n",
    "KNN Regressor: KNN is used as a regressor when the task is to predict a continuous numerical value for a data point. In this case, the predicted value is typically the average (or weighted average) of the values of the k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ee1e1-0a0a-4302-b68f-f4b1b12cd1a1",
   "metadata": {},
   "source": [
    "# Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd5bca-d506-43f2-9d34-29bc26c3795c",
   "metadata": {},
   "source": [
    "The performance of KNN can be measured using various evaluation metrics depending on whether it's used for classification or regression tasks. Common metrics include:\n",
    "Classification: Accuracy, precision, recall, F1-score, ROC AUC, confusion matrix.\n",
    "Regression: Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-squared (R2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca938a-4374-4d80-b2f8-17a6747435d3",
   "metadata": {},
   "source": [
    "# Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1cf9b-a83b-49dc-8270-ab49f4170027",
   "metadata": {},
   "source": [
    "The curse of dimensionality refers to the phenomenon where the performance of KNN deteriorates as the number of dimensions (features) in the dataset increases. In high-dimensional spaces, data points become increasingly sparse, and the notion of distance between points loses its meaning. As a result, KNN may struggle to find meaningful neighbors and can become computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a4600-06c1-42d2-8e33-9064f1ec755b",
   "metadata": {},
   "source": [
    "# Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808a524-4927-4f82-bf46-41dd76f7bd68",
   "metadata": {},
   "source": [
    "Handling missing values in KNN depends on the nature of the problem and the specific dataset. Some common approaches include:\n",
    "Imputation: Fill missing values with reasonable estimates (e.g., mean, median, mode) based on available data.\n",
    "Distance weighting: Modify the distance metric to account for missing values or assign higher distances to data points with missing values.\n",
    "Use of specialized algorithms: There are variations of KNN that are designed to handle missing values more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f1abe-087b-44d8-8c15-07fedc229eb9",
   "metadata": {},
   "source": [
    "# Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea80ab-3d94-4520-8d13-cb61867ce188",
   "metadata": {},
   "source": [
    "KNN Classifier: Suitable for problems where the target variable is categorical or consists of class labels. It's commonly used for tasks like image classification, spam detection, and sentiment analysis.\n",
    "KNN Regressor: Appropriate for problems where the target variable is continuous and numeric. It's often used for tasks like predicting house prices, stock prices, or any regression problem where numeric values are the desired output.\n",
    "The choice between KNN classifier and regressor depends on the nature of the problem and the type of data you're working with. Use KNN classifier for classification tasks and KNN regressor for regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b031762-a63f-4e8a-b5c6-d0e9bd121679",
   "metadata": {},
   "source": [
    "# Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262b2b9-3974-4e09-8928-f4131b8c489a",
   "metadata": {},
   "source": [
    "Strengths:\n",
    "\n",
    "Simple to understand and implement.\n",
    "\n",
    "Can work well for both linear and non-linear data.\n",
    "\n",
    "No assumption about the underlying data distribution.\n",
    "\n",
    "Weaknesses:\n",
    "\n",
    "Sensitive to the choice of K.\n",
    "\n",
    "Computationally expensive for large datasets.\n",
    "\n",
    "Affected by the curse of dimensionality in high-dimensional spaces.\n",
    "\n",
    "May perform poorly when data is imbalanced.\n",
    "\n",
    "To address these weaknesses, consider techniques like feature selection or dimensionality reduction, cross-validation for K selection, and using distance weighting schemes to mitigate the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd800e-b732-406b-94f2-183ce09d96bc",
   "metadata": {},
   "source": [
    "# Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d07eb-b68f-4ef6-9f77-6e3f42f1b8d2",
   "metadata": {},
   "source": [
    "Euclidean Distance: Euclidean distance measures the straight-line distance between two points in a multidimensional space. It is calculated as the square root of the sum of squared differences between corresponding coordinates.\n",
    "Manhattan Distance: Manhattan distance, also known as the L1 distance or city block distance, measures the distance between two points as the sum of the absolute differences of their coordinates along each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8bc5f2-debb-4ecd-bd0b-a74810a282ea",
   "metadata": {},
   "source": [
    "# Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf184278-a59b-4fb9-bda6-f1ae98763f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
